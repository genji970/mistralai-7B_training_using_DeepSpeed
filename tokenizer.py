IGNORE_INDEX = -100

def tokenize(examples):
    EOS_TOKEN = tokenizer.eos_token or ""

    # ë¦¬ìŠ¤íŠ¸ ë³´ì¥
    prompts = examples["prompt"] if isinstance(examples["prompt"], list) else [examples["prompt"]]
    completions = examples["completion"] if isinstance(examples["completion"], list) else [examples["completion"]]
    completions = [c + EOS_TOKEN for c in completions]

    # ê°ê° í† í¬ë‚˜ì´ì¦ˆ
    model_inputs = tokenizer(prompts, truncation=True, padding=False)
    label_outputs = tokenizer(completions, truncation=True, padding=False)

    input_ids = model_inputs["input_ids"]
    labels = label_outputs["input_ids"]

    # ğŸ”§ label ë¹„ì–´ ìˆê±°ë‚˜ 2ì°¨ì› ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
    for i in range(len(labels)):
        if len(labels[i]) == 0:
            labels[i] = [IGNORE_INDEX]

    # ğŸ”§ ì •ë ¬ê³¼ íŒ¨ë”©
    padded = tokenizer.pad(
        {
            "input_ids": input_ids,
            "attention_mask": model_inputs["attention_mask"],
            "labels": labels,
        },
        padding=True,
        return_tensors=None
    )

    return padded
